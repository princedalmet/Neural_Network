{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4576cc7d-948f-4549-92aa-371baba67c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7a42cb8-a250-4fca-a825-d3117e7937f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "9\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "words = open('name.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words))\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b71c4f-144b-4bff-b58b-5d389909c21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10bd7544-e8c9-4903-b5c7-018be170d6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1125, 3]) torch.Size([1125])\n",
      "torch.Size([133, 3]) torch.Size([133])\n",
      "torch.Size([132, 3]) torch.Size([132])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e051b4-5b4f-4200-9ea8-cc7ce66f5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t): # dt is use for manually calucalted gradient and t.grad is usefull to calculate gredient computed by pYtroch\n",
    "    \n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aaaeb51-9a42-40bb-9874-661b394223c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5) #initialized weight of first hidden layer\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1#\n",
    "\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "bngain = torch.randn((1, n_hidden))* 0.1 + 1.0 #gain Batch normaliaztion normalise the o/p of each layer\n",
    "bnbias = torch.randn((1, n_hidden))* 0.1# bias Btach normalization with small random values use to shift the normalize output before passing to activation function \n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21082308-ac64-4088-8b2f-fbf3913c8205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 375,  309,  762,  139,  254,  109,  661,  947,   38,  299,   10,   21,\n",
      "         651,  346,  206,  886,  418,  817,  333,  933, 1025,  189,  258,  155,\n",
      "         662,   88,  859,  267,  889,  533,   36,  539])\n",
      "---------------------------\n",
      "tensor([[ 4, 12,  5],\n",
      "        [ 0, 18, 25],\n",
      "        [19, 21, 13],\n",
      "        [ 0,  0,  1],\n",
      "        [12, 12,  1],\n",
      "        [14,  9, 20],\n",
      "        [ 0,  0,  0],\n",
      "        [ 1, 12,  1],\n",
      "        [ 0,  0,  6],\n",
      "        [ 0,  0,  0],\n",
      "        [15, 14,  4],\n",
      "        [ 0, 10, 15],\n",
      "        [25, 20, 15],\n",
      "        [ 0,  0, 14],\n",
      "        [ 4,  1, 14],\n",
      "        [ 0,  0,  0],\n",
      "        [12,  5, 14],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  0],\n",
      "        [ 5, 12,  9],\n",
      "        [ 5, 18,  5],\n",
      "        [ 0,  0, 10],\n",
      "        [23,  9, 12],\n",
      "        [ 9, 15, 12],\n",
      "        [ 0,  0,  3],\n",
      "        [ 8, 12,  5],\n",
      "        [ 0,  5, 22],\n",
      "        [ 5, 18, 12],\n",
      "        [ 1, 12,  5],\n",
      "        [12, 25, 14],\n",
      "        [ 9, 14,  5],\n",
      "        [12,  1, 14]])\n",
      "-------------------------------\n",
      "tensor([25, 12, 13, 12,  0, 25,  3, 14,  1,  1, 25,  3, 14,  1,  9,  1, 20,  1,\n",
      "        18, 12, 14,  1, 12,  5, 15, 25,  5,  5, 24,  0,  0,  9])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "print(ix)\n",
    "print(\"---------------------------\")\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "\n",
    "print(Xb)\n",
    "print(\"-------------------------------\")\n",
    "print(Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb9d059-e3f1-46ea-836e-6901f2bcf34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6657, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)#compute mean of acti. along batch dimension\n",
    "bndiff = hprebn - bnmeani #differecne betw acti. and mean\n",
    "bndiff2 = bndiff**2 #to calculate the varience\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) #Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5 #inverse the stand deviation\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b3b96c-db83-4f25-b47f-e82d89d2b360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs)#\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fc639cf-2f42-45a8-ad63-f2e3265ba6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6656672954559326 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a268705-57ce-4832-bd6a-9087f67a56e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.28642737865448e-09\n"
     ]
    }
   ],
   "source": [
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f31da9fa-8404-4dd8-b3a8-a50dc7b601d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed76c9a6-0ae8-4127-9310-20b7667a9405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0708, 0.0802, 0.0218, 0.0409, 0.0101, 0.0998, 0.0478, 0.0322, 0.0311,\n",
       "        0.0325, 0.0510, 0.0364, 0.0308, 0.0127, 0.0263, 0.0104, 0.0315, 0.0183,\n",
       "        0.0495, 0.0179, 0.0216, 0.0344, 0.0230, 0.0522, 0.0572, 0.0439, 0.0155],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88e01c46-ce91-4413-abff-07af40c5021d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0708,  0.0802,  0.0218,  0.0409,  0.0101,  0.0998,  0.0478,  0.0322,\n",
       "         0.0311,  0.0325,  0.0510,  0.0364,  0.0308,  0.0127,  0.0263,  0.0104,\n",
       "         0.0315,  0.0183,  0.0495,  0.0179,  0.0216,  0.0344,  0.0230,  0.0522,\n",
       "         0.0572, -0.9561,  0.0155], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab0e04cd-7b92-47c1-ae6d-660ac23bfadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3283e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad967147-aaba-43ba-94d5-d20098b99bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa70e9c9a50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a844ed3-64fa-456d-994f-85bf7256e0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(3.2659, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a6582e-b691-41e9-8bad-636d04914cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f35d3610-0f47-4860-ade4-8f8931b7bcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5c9b64-35ae-4743-9784-c534b96435d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.6488\n",
      "  10000/ 200000: 1.1525\n",
      "  20000/ 200000: 1.3254\n",
      "  30000/ 200000: 0.9927\n",
      "  40000/ 200000: 1.2677\n",
      "  50000/ 200000: 0.7430\n",
      "  60000/ 200000: 0.9390\n",
      "  70000/ 200000: 0.6153\n",
      "  80000/ 200000: 1.1039\n",
      "  90000/ 200000: 0.9333\n",
      " 100000/ 200000: 0.8909\n",
      " 110000/ 200000: 1.1098\n",
      " 120000/ 200000: 0.7530\n",
      " 130000/ 200000: 0.5653\n",
      " 140000/ 200000: 0.5961\n",
      " 150000/ 200000: 0.6890\n",
      " 160000/ 200000: 0.4331\n",
      " 170000/ 200000: 1.3059\n",
      " 180000/ 200000: 0.8198\n",
      " 190000/ 200000: 1.0003\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58adce22-c1e4-4f64-88c2-298d43969ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a570eff-17b6-43b7-b6e9-6c43ff02cf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.860369086265564\n",
      "val 4.067604064941406\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fc2c854-d1f0-49fc-a70d-2e726f0462cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eden.\n",
      "amary.\n",
      "seren.\n",
      "dia.\n",
      "alerine.\n",
      "scarlotte.\n",
      "adelizabeth.\n",
      "emi.\n",
      "jade.\n",
      "kennedy.\n",
      "aalie.\n",
      "teagan.\n",
      "aline.\n",
      "addison.\n",
      "gracie.\n",
      "juliette.\n",
      "parker.\n",
      "finley.\n",
      "victoriana.\n",
      "eline.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0b4a3-0c6b-48e2-bb3b-8aea216629f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New_project",
   "language": "python",
   "name": "new_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
